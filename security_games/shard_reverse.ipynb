{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zf/anaconda3/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:17<00:00,  2.21s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from desi_llm.common.utils import shard\n",
    "from llm_bases.chatglm6b import ChatGML6B\n",
    "\n",
    "chatglm6b = ChatGML6B()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(word: str):\n",
    "    token_id = chatglm6b.tokenizer(word)['input_ids'][0]\n",
    "    embedding = chatglm6b.condgen.transformer.word_embeddings.weight[token_id]\n",
    "    embedding = embedding.float().to(\"cuda:2\")\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import lstsq\n",
    "\n",
    "\n",
    "def test_recover_word(word: str, noise_scale: float, n_shards: int=10, lstsq_batch: int=32):\n",
    "    raw_embedding = get_word_embedding(word)\n",
    "    print(f\"Embedding scale: {torch.std(raw_embedding).item():.4f}\")\n",
    "    input_embedding = raw_embedding + torch.normal(0, noise_scale, raw_embedding.shape, device=raw_embedding.device, dtype=raw_embedding.dtype)\n",
    "    random_shards, random_coefs = shard(input_embedding, n_shards)\n",
    "    print(f\"Random coefs: {random_coefs}, sum: {torch.sum(random_coefs).item()}\")\n",
    "\n",
    "    def create_tensor(x):\n",
    "        return torch.tensor(x, dtype=raw_embedding.dtype, device=raw_embedding.device)\n",
    "\n",
    "    k, d = random_shards.shape\n",
    "    solved_coefs = torch.linalg.lstsq(random_shards.T, raw_embedding[:, None])[0]\n",
    "    #  [d, k], [k, 1]          [d, 1]\n",
    "    err = random_shards.T @ solved_coefs - raw_embedding[:, None]  # [batch, dim, 1]\n",
    "    print(f\"Errors by given the original embedding: {torch.sqrt(torch.mean(torch.square(err))).item():4f}, sum: {torch.sum(solved_coefs).item()}\")\n",
    "\n",
    "    least_square_errors = []\n",
    "    all_coefsums = []\n",
    "    for i in tqdm.tqdm(range(chatglm6b.n_tokens // lstsq_batch + 1)):\n",
    "        candiate_embedding = chatglm6b.condgen.transformer.word_embeddings.weight.data[i * lstsq_batch : (i + 1) * lstsq_batch].float().to(random_shards.device)\n",
    "        solved_coefs = torch.linalg.lstsq(\n",
    "            torch.cat([random_shards.T[None, ...], create_tensor([[[1.]]]).expand(1, 1, k)], dim=1), \n",
    "            torch.cat([candiate_embedding[..., None], create_tensor([[[1.]]]).expand(lstsq_batch, 1, 1)], dim=1))[0]\n",
    "         [batch, d, k], [batch, k, 1]          [batch, d, 1]\n",
    "        # solved_coefs = torch.linalg.lstsq(random_shards.T[None, ...], candiate_embedding[..., None])[0]\n",
    "\n",
    "        # all_coefsums.extend(torch.sum(solved_coefs[..., 0], dim=-1).tolist())\n",
    "        # errs = random_shards.T[None, ...] @ solved_coefs - candiate_embedding[..., None]  # [batch, d, 1]\n",
    "        # least_square_errors.extend(torch.sqrt(torch.mean(torch.square(errs[:, :, 0]), dim=-1)).tolist())\n",
    "    # Check the goodness of the solution\n",
    "\n",
    "    asc_indices = np.argsort(least_square_errors)\n",
    "    pos = np.searchsorted(np.array(least_square_errors)[asc_indices], noise_scale)\n",
    "    print(f\"Order of the target: {pos}\")\n",
    "    for i in asc_indices[max(0, pos - 1000): pos + 1000]:\n",
    "        if i == asc_indices[pos]:\n",
    "            print(\"================\")\n",
    "        if 0.8 < all_coefsums[i] < 1.2:\n",
    "            print(f\"{least_square_errors[i]:.6f}\\t{i}\\t{chatglm6b.tokenizer.decode(i)}\\t{all_coefsums[i]:.4f}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding scale: 0.0113\n",
      "Random coefs: tensor([-4.0313,  3.2110,  0.7622,  1.3049, -0.7019, -3.8832,  0.7295, -1.2794,\n",
      "        -0.3520,  3.4300,  1.4151, -2.2342,  3.7410,  0.5230, -2.4572,  0.0692,\n",
      "         4.4390, -0.2464, -2.2110, -4.9531,  1.4838, -1.3954, -4.6838, -0.3439,\n",
      "        -2.2473,  1.8736,  2.7595,  0.6757, -1.3311, -2.1164,  2.4726,  1.8249,\n",
      "        -1.9824, -1.7143, -3.5250, -3.3120,  4.3333,  2.7268,  4.7316, -3.8280,\n",
      "        -0.7841, -2.5892,  0.1153, -1.8021, -3.3790, -4.6919,  2.4585,  4.5744,\n",
      "         2.0065,  0.2911], device='cuda:2'), sum: -10.123047828674316\n",
      "Errors by given the original embedding: 0.004526, sum: -405.811767578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4063/4063 [00:27<00:00, 148.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order of the target: 1\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "test_recover_word(\"Hearing\", 0.005, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
