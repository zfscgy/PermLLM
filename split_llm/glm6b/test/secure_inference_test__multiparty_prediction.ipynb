{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "from simple_socket.zf_socket import SocketServer\n",
    "from split_llm.common.communication import Node\n",
    "from split_llm.common.communication import Communication, Node, SimulatedCommunication\n",
    "from split_llm.common.real_communication import RealCommunication\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "\n",
    "# Set up communication\n",
    "\n",
    "address_dict = {\n",
    "    \"127.0.0.1:9100\": \"n0\",\n",
    "    \"127.0.0.1:9101\": \"n1\",\n",
    "    \"127.0.0.1:9102\": \"n2\"\n",
    "}\n",
    "sock0 = SocketServer(\"127.0.0.1:9100\", address_dict, 1000)\n",
    "sock1 = SocketServer(\"127.0.0.1:9101\", address_dict, 1000)\n",
    "sock2 = SocketServer(\"127.0.0.1:9102\", address_dict, 1000)\n",
    "\n",
    "time.sleep(1) # Wait the server to start listening\n",
    "\n",
    "sock0.connect_all()\n",
    "sock1.connect_all()\n",
    "sock2.connect_all()\n",
    "\n",
    "comm0 = RealCommunication([\"n0\", \"n1\", \"n2\"], {\"n0\": sock0}, tensor_device=device)\n",
    "comm1 = RealCommunication([\"n0\", \"n1\", \"n2\"], {\"n1\": sock1}, tensor_device=device)\n",
    "comm2 = RealCommunication([\"n0\", \"n1\", \"n2\"], {\"n2\": sock2}, tensor_device=device)\n",
    "# comm0 = comm1 = comm2 = SimulatedCommunication([\"n0\", \"n1\", \"n2\"])\n",
    "# comm0.new_stage(\"Test\")\n",
    "n0 = Node(comm0, \"n0\")\n",
    "n1 = Node(comm1, \"n1\")\n",
    "n2 = Node(comm2, \"n2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:09<00:00,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llm_bases.chatglm6b import ChatGML6B\n",
    "glm = ChatGML6B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n0.space.word_embedding = glm.condgen.transformer.word_embeddings.weight.float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "hs = torch.normal(0, 1, [4096]).cuda()\n",
    "h0 = torch.normal(0, 10, [4096]).cuda()\n",
    "h1 = hs - h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected prediction:  5\n"
     ]
    }
   ],
   "source": [
    "prediction = torch.argmax(glm.condgen.lm_head.cuda()(hs))\n",
    "print(\"Expected prediction: \", prediction.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete complete!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import sys\n",
    "    del sys.modules['split_llm.glm6b.secure_inference']\n",
    "    del sys.modules['homomorphic_encryption.bfv']\n",
    "    print(\"delete complete!\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "from split_llm.glm6b.secure_inference import GLM_PredictionProtocol, GLM_EmbeddingRetrievalProtocol, GLMConfig\n",
    "from split_llm.common.torch_utils import relative_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_protocol0 = GLM_EmbeddingRetrievalProtocol(n0, Node.from_remote_name(\"n1\"), Node.from_remote_name(\"n2\"), 10, device=\"cuda\")\n",
    "embedding_protocol1 = GLM_EmbeddingRetrievalProtocol(Node.from_remote_name(\"n0\"), n1, Node.from_remote_name(\"n2\"), 10, device=\"cuda\")\n",
    "embedding_protocol2 = GLM_EmbeddingRetrievalProtocol(Node.from_remote_name(\"n0\"), Node.from_remote_name(\"n1\"), n2, 10, device=\"cuda\")\n",
    "\n",
    "prediction_protocol0 = GLM_PredictionProtocol(n0, Node.from_remote_name(\"n1\"), Node.from_remote_name(\"n2\"), embedding_protocol0.name, 10, device=\"cuda\")\n",
    "prediction_protocol1 = GLM_PredictionProtocol(Node.from_remote_name(\"n0\"), n1, Node.from_remote_name(\"n2\"), embedding_protocol1.name, 10, device=\"cuda\")\n",
    "prediction_protocol2 = GLM_PredictionProtocol(Node.from_remote_name(\"n0\"), Node.from_remote_name(\"n1\"), n2, embedding_protocol2.name, 10, device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m emb_prepare1\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m      8\u001b[0m emb_prepare2\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m----> 9\u001b[0m \u001b[43membedding_protocol0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m emb_prepare1\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m     11\u001b[0m emb_prepare2\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m~/autodl-tmp/PermLLM/split_llm/glm6b/secure_inference.py:857\u001b[0m, in \u001b[0;36mGLM_EmbeddingRetrievalProtocol.prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    855\u001b[0m     embedding: nn\u001b[38;5;241m.\u001b[39mLinear \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn0\u001b[38;5;241m.\u001b[39mspace\u001b[38;5;241m.\u001b[39mword_embedding\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn0\u001b[38;5;241m.\u001b[39mstorage[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monehot_matmul_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:x\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m embedding\n\u001b[0;32m--> 857\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monehot_matmul_protocol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm_in_protocol\u001b[38;5;241m.\u001b[39mprepare()\n",
      "File \u001b[0;32m~/autodl-tmp/PermLLM/split_llm/protocols/base_protocols.py:55\u001b[0m, in \u001b[0;36mSS_Mul__CX_N0_Y_N1.prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# In node_0\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_0\u001b[38;5;241m.\u001b[39mlocal():\n\u001b[0;32m---> 55\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:beaver_u\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     x_sub_u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_0\u001b[38;5;241m.\u001b[39mstorage[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:x\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m u\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_0\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_1\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:x-u\u001b[39m\u001b[38;5;124m\"\u001b[39m, x_sub_u)\n",
      "File \u001b[0;32m~/autodl-tmp/PermLLM/split_llm/common/communication.py:105\u001b[0m, in \u001b[0;36mNode.fetch\u001b[0;34m(self, from_role, header)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, from_role: \u001b[38;5;28mstr\u001b[39m, header: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_role\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/autodl-tmp/PermLLM/split_llm/common/real_communication.py:79\u001b[0m, in \u001b[0;36mRealCommunication.fetch\u001b[0;34m(self, to_role, from_role, header)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, to_role: \u001b[38;5;28mstr\u001b[39m, from_role: \u001b[38;5;28mstr\u001b[39m, header: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 79\u001b[0m     received_header, wrapped_obj \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_server_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mto_role\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrom_role\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m received_header \u001b[38;5;241m!=\u001b[39m header:\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected header \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreceived_header\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheader\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/autodl-tmp/PermLLM/simple_socket/zf_socket.py:170\u001b[0m, in \u001b[0;36mSocketServer.recv_from\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SocketException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPeer name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m dose not exist or not connected yet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n\u001b[1;32m    169\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mother_recv_sockets[name]\n\u001b[0;32m--> 170\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[43mread_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraffic_counter_from[name] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content) \u001b[38;5;241m+\u001b[39m SocketConfig\u001b[38;5;241m.\u001b[39mlen_header \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(SocketConfig\u001b[38;5;241m.\u001b[39mstart_flag)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content\n",
      "File \u001b[0;32m~/autodl-tmp/PermLLM/simple_socket/zf_socket.py:37\u001b[0m, in \u001b[0;36mread_socket\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(content) \u001b[38;5;241m<\u001b[39m content_len:\n\u001b[1;32m     36\u001b[0m         content \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mrecv(content_len \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(content))\n\u001b[0;32m---> 37\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m content\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "\n",
    "# Prepare embedding_retrieval\n",
    "emb_prepare1 = threading.Thread(target=embedding_protocol1.prepare)\n",
    "emb_prepare2 = threading.Thread(target=embedding_protocol2.prepare)\n",
    "emb_prepare1.start()\n",
    "emb_prepare2.start()\n",
    "embedding_protocol0.prepare()\n",
    "emb_prepare1.join()\n",
    "emb_prepare2.join()\n",
    "\n",
    "print(\"embedding_retrieval prepare finished\")\n",
    "\n",
    "prepare1 = threading.Thread(target=prediction_protocol1.prepare)\n",
    "prepare2 = threading.Thread(target=prediction_protocol2.prepare)\n",
    "prepare1.start()\n",
    "prepare2.start()\n",
    "prediction_protocol0.prepare()\n",
    "prepare1.join()\n",
    "prepare2.join()\n",
    "\n",
    "print(\"prediction prepare finished\")\n",
    "\n",
    "offline1 = threading.Thread(target=prediction_protocol1.offline_execute)\n",
    "offline2 = threading.Thread(target=prediction_protocol2.offline_execute)\n",
    "offline1.start()\n",
    "offline2.start()\n",
    "prediction_protocol0.offline_execute()\n",
    "offline1.join()\n",
    "offline2.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed prediction:  [94781]\n"
     ]
    }
   ],
   "source": [
    "n0.storage[f\"{prediction_protocol0.name}:x0\"] = h0\n",
    "n1.storage[f\"{prediction_protocol1.name}:x1\"] = h1\n",
    "online1 = threading.Thread(target=prediction_protocol1.online_execute)\n",
    "online2 = threading.Thread(target=prediction_protocol2.online_execute)\n",
    "online1.start()\n",
    "online2.start()\n",
    "prediction_protocol0.online_execute()\n",
    "online1.join()\n",
    "online2.join()\n",
    "print(\"Computed prediction: \", n1.storage[f\"{prediction_protocol1.name}:z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([130528, 4096])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2.storage['GLM__EmbeddingLayer/onehot_matmul:beaver_u'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GLM__EmbeddingLayer/onehot_matmul:x-u'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mn1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGLM__EmbeddingLayer/onehot_matmul:x-u\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mKeyError\u001b[0m: 'GLM__EmbeddingLayer/onehot_matmul:x-u'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
