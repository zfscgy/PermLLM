{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:08<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "from llm_bases.chatglm6b import ChatGML6B\n",
    "glm = ChatGML6B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_llm.glm6b.wrapped_layer import Attention_GLM_Wrapped, FeedForward_GLM_Wrapped, copy_attention, copy_feedforward\n",
    "from split_llm.common.torch_utils import relative_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_glm_layers = glm.condgen.transformer.layers\n",
    "attentions: List[Attention_GLM_Wrapped] = []\n",
    "ffs: List[FeedForward_GLM_Wrapped] = []\n",
    "for i in range(28):\n",
    "    transformer_layer = raw_glm_layers[i].float()\n",
    "    attn_wrapped = Attention_GLM_Wrapped(4096, 32, i)\n",
    "    copy_attention(transformer_layer, attn_wrapped)\n",
    "    attentions.append(attn_wrapped.cuda())\n",
    "\n",
    "    ff_wrapped = FeedForward_GLM_Wrapped(4096, 32, i)\n",
    "    if i == 27:\n",
    "        copy_feedforward(transformer_layer, None, ff_wrapped)\n",
    "    else:\n",
    "        copy_feedforward(transformer_layer, raw_glm_layers[i + 1].float(), ff_wrapped)\n",
    "    ffs.append(ff_wrapped.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_llm.glm6b.utils import generate_attention_mask, generate_position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the GLM model weights (embeddings at the beginning and the end) into CUDA-float\n",
    "\n",
    "glm.condgen.transformer.word_embeddings.float().cuda()\n",
    "glm.condgen.lm_head.float().cuda()\n",
    "\n",
    "layernorm0 = glm.condgen.transformer.layers[0].input_layernorm.float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_hidden_scales(query: str, generation_length: int):\n",
    "    input_ids, position_ids, attention_masks = glm.get_tokenization(query)\n",
    "    input_ids = input_ids.cuda()\n",
    "    position_ids = position_ids.cuda()\n",
    "    attention_masks = attention_masks.cuda()\n",
    "\n",
    "    original_length = len(input_ids[0])\n",
    "    \n",
    "    all_scales = []\n",
    "    for i in range(generation_length):\n",
    "        # print(f\"Generate {i}-th token\")\n",
    "        # Here the first layernorm is moved\n",
    "        h = layernorm0(glm.get_initial_state(input_ids))\n",
    "        layer_scales = []\n",
    "        for j in range(28):\n",
    "            # print(\"Layer\", j)\n",
    "            # Forward to the i-th attention layer    \n",
    "            scale_h_in = h.abs().max().item()\n",
    "\n",
    "            # Attention module\n",
    "            attn_layer: Attention_GLM_Wrapped = attentions[j]\n",
    "            q, k, v = attn_layer.generate_qkv(h, position_ids)\n",
    "            scale_v = v.abs().max().item()  # Record the scale of V\n",
    "            attn_scores = attn_layer.generate_logit_scores(q, k)\n",
    "            scale_attn_score = attn_scores.abs().max().item()  # Record the scale since here the plaintext is used\n",
    "            softmax_scores = attn_layer.generate_softmax_scores(attn_scores)\n",
    "            weighted_v = attn_layer.generate_weighted_values(softmax_scores, v)\n",
    "            attn_out = weighted_v @ attn_layer.attn_out_weight.T + attn_layer.attn_out_bias\n",
    "            # Feedforward module\n",
    "            ff_layer: FeedForward_GLM_Wrapped = ffs[j]\n",
    "            h0 = ff_layer.layernorm_in(attn_out + h * (2 * 28) ** 0.5)\n",
    "            h1 = ff_layer.mlp_dense_in(h0)\n",
    "            \n",
    "            scale_mlp_hidden = h1.abs().max().item()\n",
    "            h2 = F.gelu(h1)\n",
    "\n",
    "            #  h2 = gelu_openai(h1)\n",
    "            #  Those two gelu implementations do not have significant difference\n",
    "            h3 = ff_layer.mlp_dense_out(h2)\n",
    "            h4 = h3 + ff_layer.residual_coef * h0\n",
    "            h5 = ff_layer.layernorm_out(h4)\n",
    "\n",
    "            h = h5\n",
    "\n",
    "            layer_scales.append([scale_h_in, scale_v, scale_attn_score, scale_mlp_hidden])\n",
    "\n",
    "        logits = glm.condgen.lm_head(h).permute(1, 0, 2).contiguous()[0, -1, :glm.n_tokens]\n",
    "        # Get the logits on the next position\n",
    "        next_id = torch.argmax(logits)\n",
    "        # print(\"Next ID\", next_id)\n",
    "\n",
    "        if next_id == glm.condgen.generation_config.eos_token_id:\n",
    "            break\n",
    "        input_ids = torch.cat([input_ids, torch.tensor([[next_id]]).cuda()], dim=-1)  # Append the last id\n",
    "        new_seq_len = len(input_ids[0])\n",
    "        position_ids = generate_position_ids(original_length, new_seq_len).cuda()\n",
    "        # print(position_ids)\n",
    "        all_scales.append(layer_scales)\n",
    "    \n",
    "    token_ids = input_ids[0][original_length:].tolist()\n",
    "    print(token_ids)\n",
    "    print(glm.decode(token_ids))\n",
    "    return np.array(all_scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:717: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608935911/work/torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19316, 5, 128788, 35, 1372, 129, 115, 4418, 120, 788, 31]\n",
      "Hello 👍! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "scales = analyze_hidden_scales(\"Hello\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41.12500763 19.31932831 25.2648735  32.29057312]\n",
      " [58.48934937 16.72546196 18.4454422  18.62054825]\n",
      " [59.89986801  8.33433437 19.08116913 13.16208076]\n",
      " [59.77453995 11.97554684 20.70600319 10.75597191]\n",
      " [60.81726837 10.28095436 19.48379517 13.32979965]\n",
      " [61.65838242 10.48189735 24.07427406 11.46224022]\n",
      " [59.78767014 13.86101818 15.82366657  9.56827068]\n",
      " [54.31472397 12.87061596 22.50842094 10.48479462]\n",
      " [54.08573151 12.18045807 26.48773003 13.21073627]\n",
      " [60.27223969 12.03366661 21.73172188 10.63670063]\n",
      " [63.42442322 11.79520321 21.94503975 13.76262283]\n",
      " [63.14886475 10.18587685 21.80389595 10.65892792]\n",
      " [68.64946747 10.64644051 23.12402916 11.56313801]\n",
      " [65.92312622 10.57049942 26.07779884 10.45457745]\n",
      " [67.54730225 10.21110439 14.49261379 12.66041183]\n",
      " [61.51429749  8.75083542 14.03304482 11.71735096]\n",
      " [58.00505829  9.42823505 22.04002571 12.25470924]\n",
      " [52.15565491  9.21329308 16.26906204 11.69371414]\n",
      " [49.33687973 11.47721958 14.51432228 13.43934155]\n",
      " [46.26225281 11.33680058 16.42205429 10.92327881]\n",
      " [47.55424881 10.40440559 19.21019936 11.18385983]\n",
      " [51.79199982  9.79139805 16.70532799 13.22411156]\n",
      " [57.22212219 12.08496857 12.64883232 13.38383198]\n",
      " [64.27793121  9.43602085 23.42529678 26.35367393]\n",
      " [59.92113876 10.5859642  15.02228546 25.3962822 ]\n",
      " [58.05392456  9.98033524 21.26204681 11.19742489]\n",
      " [49.66976547 11.53038406 10.70756054 14.2645092 ]\n",
      " [47.91917038 15.51841545 12.67823887 10.8586483 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.max(scales, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_scale = 10000_4214\n",
    "\n",
    "torch.tensor(original_scale + 34.52) - torch.tensor(original_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  0, QKV max: 0.2466, AttnOut max: 0.6855\n",
      "Layer  1, QKV max: 0.1552, AttnOut max: 0.5874\n",
      "Layer  2, QKV max: 0.1327, AttnOut max: 0.3381\n",
      "Layer  3, QKV max: 0.1476, AttnOut max: 0.4224\n",
      "Layer  4, QKV max: 0.1367, AttnOut max: 0.2632\n",
      "Layer  5, QKV max: 0.1354, AttnOut max: 0.3162\n",
      "Layer  6, QKV max: 0.1494, AttnOut max: 0.6372\n",
      "Layer  7, QKV max: 0.1163, AttnOut max: 0.4460\n",
      "Layer  8, QKV max: 0.1791, AttnOut max: 0.6919\n",
      "Layer  9, QKV max: 0.1908, AttnOut max: 0.8496\n",
      "Layer 10, QKV max: 0.1379, AttnOut max: 0.3650\n",
      "Layer 11, QKV max: 0.1356, AttnOut max: 0.5137\n",
      "Layer 12, QKV max: 0.1398, AttnOut max: 0.3311\n",
      "Layer 13, QKV max: 0.1420, AttnOut max: 0.8291\n",
      "Layer 14, QKV max: 0.1332, AttnOut max: 0.6045\n",
      "Layer 15, QKV max: 0.1268, AttnOut max: 0.8643\n",
      "Layer 16, QKV max: 0.1398, AttnOut max: 0.3745\n",
      "Layer 17, QKV max: 0.1396, AttnOut max: 0.5762\n",
      "Layer 18, QKV max: 0.1377, AttnOut max: 0.3770\n",
      "Layer 19, QKV max: 0.1519, AttnOut max: 0.6987\n",
      "Layer 20, QKV max: 0.1560, AttnOut max: 0.6221\n",
      "Layer 21, QKV max: 0.1562, AttnOut max: 0.6138\n",
      "Layer 22, QKV max: 0.1604, AttnOut max: 0.6016\n",
      "Layer 23, QKV max: 0.1735, AttnOut max: 0.5801\n",
      "Layer 24, QKV max: 0.1919, AttnOut max: 0.5786\n",
      "Layer 25, QKV max: 0.2264, AttnOut max: 0.5513\n",
      "Layer 26, QKV max: 0.1904, AttnOut max: 0.8110\n",
      "Layer 27, QKV max: 0.1741, AttnOut max: 1.1348\n"
     ]
    }
   ],
   "source": [
    "# Check the scale of important weights\n",
    "# This is helpful for deciding the mask_size\n",
    "\n",
    "\n",
    "for i, (attn, ff) in enumerate(zip(attentions, ffs)):\n",
    "    print(f\"Layer {i:2d}, QKV max: {torch.max(attn.qkv_weight).item():4.4f}, AttnOut max: {torch.max(attn.attn_out_weight).item():4.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): Identity()\n",
       " )]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
