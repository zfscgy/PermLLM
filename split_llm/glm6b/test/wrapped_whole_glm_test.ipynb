{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:09<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "from llm_bases.chatglm6b import ChatGML6B\n",
    "glm = ChatGML6B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_llm.glm6b.wrapped_layer import Attention_GLM_Wrapped, FeedForward_GLM_Wrapped, copy_attention, copy_feedforward\n",
    "from split_llm.common.torch_utils import relative_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_glm_layers = glm.condgen.transformer.layers\n",
    "attentions: List[Attention_GLM_Wrapped] = []\n",
    "ffs: List[FeedForward_GLM_Wrapped] = []\n",
    "for i in range(28):\n",
    "    transformer_layer = raw_glm_layers[i].float()\n",
    "    attn_wrapped = Attention_GLM_Wrapped(4096, 32, i)\n",
    "    copy_attention(transformer_layer, attn_wrapped)\n",
    "    attentions.append(attn_wrapped.cuda())\n",
    "\n",
    "    ff_wrapped = FeedForward_GLM_Wrapped(4096, 32, i)\n",
    "    if i == 27:\n",
    "        copy_feedforward(transformer_layer, None, ff_wrapped)\n",
    "        ff_wrapped.layernorm_out = glm.condgen.transformer.final_layernorm.float().cuda()\n",
    "    else:\n",
    "        copy_feedforward(transformer_layer, raw_glm_layers[i + 1].float(), ff_wrapped)\n",
    "    ffs.append(ff_wrapped.cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_llm.glm6b.utils import generate_attention_mask, generate_position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the GLM model weights (embeddings at the beginning and the end) into CUDA-float\n",
    "\n",
    "glm.condgen.transformer.word_embeddings.float().cuda()\n",
    "glm.condgen.lm_head.float().cuda()\n",
    "\n",
    "layernorm0 = glm.condgen.transformer.layers[0].input_layernorm.float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_hidden_scales(query: str, generation_length: int):\n",
    "    input_ids, position_ids, attention_masks = glm.get_tokenization(query)\n",
    "    \n",
    "    \n",
    "    original_length = len(input_ids[0])\n",
    "    input_ids = input_ids.cuda()\n",
    "    start_id = input_ids[0, -1]\n",
    "    input_ids = input_ids[:, :-1]\n",
    "    position_ids = position_ids.cuda()[:, :, :-1]\n",
    "    # The start_id has an attention mask\n",
    "\n",
    "    \n",
    "    all_scales = []\n",
    "    previous_k = dict()\n",
    "    previous_v = dict()\n",
    "\n",
    "    predicted_ids = []\n",
    "\n",
    "    for i in range(generation_length):\n",
    "        # print(f\"Generate {i}-th token\")\n",
    "        # Here the first layernorm is moved\n",
    "        h = layernorm0(glm.get_initial_state(input_ids))\n",
    "        layer_scales = []\n",
    "        for j in range(28):\n",
    "            # print(\"Layer\", j)\n",
    "            # Forward to the i-th attention layer    \n",
    "            scale_h_in = h.abs().max().item()\n",
    "\n",
    "            # Attention module\n",
    "            attn_layer: Attention_GLM_Wrapped = attentions[j]\n",
    "            q, k, v = attn_layer.generate_qkv(h, position_ids)\n",
    "            if j not in previous_k:\n",
    "                previous_k[j] = k\n",
    "            else:\n",
    "                previous_k[j] = torch.cat([previous_k[j], k], dim=0)\n",
    "                k = previous_k[j]\n",
    "\n",
    "            \n",
    "            if j not in previous_v:\n",
    "                previous_v[j] = v\n",
    "            else:\n",
    "                previous_v[j] = torch.cat([previous_v[j], v], dim=0)\n",
    "                v = previous_v[j]\n",
    "\n",
    "\n",
    "            scale_v = v.abs().max().item()  # Record the scale of V\n",
    "            attn_scores = attn_layer.generate_logit_scores(q, k)\n",
    "            scale_attn_score = attn_scores.abs().max().item()  # Record the scale since here the plaintext is used\n",
    "            softmax_scores = attn_layer.generate_softmax_scores(attn_scores)\n",
    "            weighted_v = attn_layer.generate_weighted_values(softmax_scores, v)\n",
    "            attn_out = weighted_v @ attn_layer.attn_out_weight.T + attn_layer.attn_out_bias\n",
    "            # Feedforward module\n",
    "            ff_layer: FeedForward_GLM_Wrapped = ffs[j]\n",
    "            h0 = ff_layer.layernorm_in(attn_out + h * (2 * 28) ** 0.5)\n",
    "            h1 = ff_layer.mlp_dense_in(h0)\n",
    "            \n",
    "            scale_mlp_hidden = h1.abs().max().item()\n",
    "            h2 = F.gelu(h1)\n",
    "\n",
    "            #  h2 = gelu_openai(h1)\n",
    "            #  Those two gelu implementations do not have significant difference\n",
    "            h3 = ff_layer.mlp_dense_out(h2)\n",
    "            h4 = h3 + ff_layer.residual_coef * h0\n",
    "            h5 = ff_layer.layernorm_out(h4)\n",
    "\n",
    "            h = h5\n",
    "\n",
    "            layer_scales.append([scale_h_in, scale_v, scale_attn_score, scale_mlp_hidden])\n",
    "\n",
    "        logits = glm.condgen.lm_head(h).permute(1, 0, 2).contiguous()[0, -1]\n",
    "        # Get the logits on the next position\n",
    "        if start_id is not None:\n",
    "            next_id = start_id\n",
    "            start_id = None\n",
    "        else:\n",
    "            next_id = torch.argmax(logits)\n",
    "            predicted_ids.append(next_id.item())\n",
    "        # print(\"Next ID\", next_id)\n",
    "\n",
    "        if next_id == glm.condgen.generation_config.eos_token_id:\n",
    "            break\n",
    "        input_ids = torch.tensor([[next_id]]).cuda()  # Append the last id\n",
    "        position_ids = generate_position_ids(original_length, original_length + len(predicted_ids))[:, :, -1:].cuda()\n",
    "        # print(position_ids)\n",
    "        all_scales.append(layer_scales)\n",
    "    \n",
    "    print(predicted_ids)\n",
    "    print(glm.decode(predicted_ids))\n",
    "    return np.array(all_scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:717: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608935911/work/torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3347, 729, 107, 104, 896, 618, 6636, 172, 1814, 114, 100, 5, 16, 15, 257, 1053, 101, 100, 494, 608, 122, 1151, 5, 10, 8, 6, 5, 10, 8, 9, 25, 6, 103, 1151, 5, 10, 8, 6, 5, 10, 8, 10, 9, 7, 256, 116, 2258, 111, 1097, 5, 9, 16, 6, 5, 9, 18, 16, 21, 6, 105, 375, 875, 928, 6, 375, 875, 7, 729, 107, 104, 16492, 102, 644, 3890, 4770, 172, 132, 156, 958, 105, 687, 611, 37188, 102, 132, 156, 100, 1319, 101, 2971, 6603, 102, 1558, 3042, 7, 4, 4, 3663, 147, 15063, 6, 729, 116, 424, 108, 147, 6781, 3418, 6, 350, 147, 2256, 103, 975, 104, 1710, 111, 100, 289, 7, 159, 7, 11, 26291, 1683, 6, 147, 12544, 111, 5638, 6, 102, 147, 3980, 101, 100, 11983, 11, 9, 18, 15190, 7, 256, 154, 5549, 2971, 37391, 102, 5768, 6, 350, 2414, 12376, 102, 5273, 6, 611, 6252, 6, 102, 1251, 5663, 7, 4, 4, 1252, 2787, 1189, 6, 729, 2037, 103, 113, 104, 6781, 1854, 6, 4111, 2971, 1558, 3042, 102, 6603, 7, 256, 132, 156, 100, 1319, 101, 2971, 22016, 6, 350, 145, 822, 103, 100, 5, 10, 8, 10, 9, 1758, 7, 130005]\n",
      "Donald Trump is a former American politician who served as the 45th President of the United States from January 20, 2017, to January 20, 2021. He was born on June 14, 1946, in New York City, New York. Trump is a businessman and real estate developer who has been involved in various business ventures and has been the subject of numerous investigations and legal challenges.\n",
      "\n",
      "During his presidency, Trump was known for his controversial policies, including his efforts to build a wall on the U.S.-Mexico border, his stance on immigration, and his handling of the COVID-19 pandemic. He also faced numerous controversies and allegations, including sexual harassment and assault, business fraud, and political contributions.\n",
      "\n",
      "After leaving office, Trump continued to be a controversial figure, facing numerous legal challenges and investigations. He has been the subject of numerous lawsuits, including one related to the 2021 election.\n"
     ]
    }
   ],
   "source": [
    "scales = analyze_hidden_scales(\"Tell me about Trump\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41.12500763 20.23776627 81.44577026 32.46224976]\n",
      " [58.23212051 19.0498085  66.00358582 15.94203758]\n",
      " [59.32036209 16.80878639 23.91127205 14.46641922]\n",
      " [59.49517441 15.66162777 34.56282043 14.58930016]\n",
      " [60.65198517 13.19166183 23.30387306 11.98528004]\n",
      " [61.47579956 12.6825695  25.85115814 16.09440613]\n",
      " [58.38166428 13.28290176 23.06168938 15.86229134]\n",
      " [54.70422363 10.57917023 40.04846954 15.8881321 ]\n",
      " [54.81056595 12.15571213 43.60208893 15.75042915]\n",
      " [60.7454834  12.19743443 42.10726547 13.49996185]\n",
      " [63.45518112 10.58491707 31.90699005 14.45426464]\n",
      " [63.10396957 10.61173725 29.22563553 12.54403114]\n",
      " [68.5146637  11.26670647 35.01483154 13.34628487]\n",
      " [65.79148102  9.85550594 37.75686264 14.56965637]\n",
      " [67.33185577 12.64821339 25.17937469 15.72464943]\n",
      " [63.43676376 11.89875889 22.96869659 13.36803341]\n",
      " [63.79126358 12.93599415 43.95756149 16.05618668]\n",
      " [57.95978546 10.56634521 20.16744423 17.47854233]\n",
      " [55.22901535 10.91130257 19.68815041 18.04890823]\n",
      " [52.47626877 14.05230904 29.36221504 15.56949806]\n",
      " [56.89764404 12.12116051 25.89892387 14.44987106]\n",
      " [57.29217911 14.41658401 25.82653427 14.45362091]\n",
      " [58.08286285 13.14338493 20.92241859 13.34285545]\n",
      " [64.92063141 11.32899857 35.94029999 26.81134415]\n",
      " [59.99600601 14.59629822 32.27801895 26.35297394]\n",
      " [58.02147293 15.47084332 30.72004318 13.13433647]\n",
      " [55.38936615 12.55370617 24.17937469 13.80871296]\n",
      " [47.782341   24.26519394 19.63368797 14.29747581]]\n"
     ]
    }
   ],
   "source": [
    "print(np.max(scales, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_scale = 10000_4214\n",
    "\n",
    "torch.tensor(original_scale + 34.52) - torch.tensor(original_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  0, QKV max: 0.2466, AttnOut max: 0.6855\n",
      "Layer  1, QKV max: 0.1552, AttnOut max: 0.5874\n",
      "Layer  2, QKV max: 0.1327, AttnOut max: 0.3381\n",
      "Layer  3, QKV max: 0.1476, AttnOut max: 0.4224\n",
      "Layer  4, QKV max: 0.1367, AttnOut max: 0.2632\n",
      "Layer  5, QKV max: 0.1354, AttnOut max: 0.3162\n",
      "Layer  6, QKV max: 0.1494, AttnOut max: 0.6372\n",
      "Layer  7, QKV max: 0.1163, AttnOut max: 0.4460\n",
      "Layer  8, QKV max: 0.1791, AttnOut max: 0.6919\n",
      "Layer  9, QKV max: 0.1908, AttnOut max: 0.8496\n",
      "Layer 10, QKV max: 0.1379, AttnOut max: 0.3650\n",
      "Layer 11, QKV max: 0.1356, AttnOut max: 0.5137\n",
      "Layer 12, QKV max: 0.1398, AttnOut max: 0.3311\n",
      "Layer 13, QKV max: 0.1420, AttnOut max: 0.8291\n",
      "Layer 14, QKV max: 0.1332, AttnOut max: 0.6045\n",
      "Layer 15, QKV max: 0.1268, AttnOut max: 0.8643\n",
      "Layer 16, QKV max: 0.1398, AttnOut max: 0.3745\n",
      "Layer 17, QKV max: 0.1396, AttnOut max: 0.5762\n",
      "Layer 18, QKV max: 0.1377, AttnOut max: 0.3770\n",
      "Layer 19, QKV max: 0.1519, AttnOut max: 0.6987\n",
      "Layer 20, QKV max: 0.1560, AttnOut max: 0.6221\n",
      "Layer 21, QKV max: 0.1562, AttnOut max: 0.6138\n",
      "Layer 22, QKV max: 0.1604, AttnOut max: 0.6016\n",
      "Layer 23, QKV max: 0.1735, AttnOut max: 0.5801\n",
      "Layer 24, QKV max: 0.1919, AttnOut max: 0.5786\n",
      "Layer 25, QKV max: 0.2264, AttnOut max: 0.5513\n",
      "Layer 26, QKV max: 0.1904, AttnOut max: 0.8110\n",
      "Layer 27, QKV max: 0.1741, AttnOut max: 1.1348\n"
     ]
    }
   ],
   "source": [
    "# Check the scale of important weights\n",
    "# This is helpful for deciding the mask_size\n",
    "\n",
    "\n",
    "for i, (attn, ff) in enumerate(zip(attentions, ffs)):\n",
    "    print(f\"Layer {i:2d}, QKV max: {torch.max(attn.qkv_weight).item():4.4f}, AttnOut max: {torch.max(attn.attn_out_weight).item():4.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " FeedForward_GLM_Wrapped(\n",
       "   (layernorm_in): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp_dense_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "   (mlp_dense_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "   (layernorm_out): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       " )]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
