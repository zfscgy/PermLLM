{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zf/anaconda3/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from split_llm.glm6b.wrapped_layer import Attention_GLM_Wrapped, copy_attention\n",
    "from split_llm.glm6b.utils import generate_position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:11<00:00,  1.46s/it]\n"
     ]
    }
   ],
   "source": [
    "from llm_bases.chatglm6b import ChatGML6B\n",
    "glm = ChatGML6B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention_GLM_Wrapped(\n",
       "  (positional_embedding): GLMPositionalEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_layer = glm.condgen.transformer.layers[0].float()\n",
    "attn_wrapped = Attention_GLM_Wrapped(4096, 32, 0)\n",
    "copy_attention(transformer_layer, attn_wrapped)\n",
    "attn_wrapped.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.normal(0, 1, [10, 1, 4096]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the hidden representations in a normal transformer layer\n",
    "\n",
    "h_qkv = x @ attn_wrapped.qkv_weight.T + attn_wrapped.qkv_bias\n",
    "qs, ks, vs = h_qkv.view(-1, 1, 32, 128 * 3).chunk(3, dim=-1)\n",
    "qs, ks = attn_wrapped.positional_embedding(qs, ks, generate_position_ids(10, 10).cuda())\n",
    "scores = attn_wrapped.generate_logit_scores(qs, ks)\n",
    "softmax_scores = attn_wrapped.generate_softmax_scores(scores, dim=1)\n",
    "weighted_v = attn_wrapped.generate_weighted_values(softmax_scores, vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete complete!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import sys\n",
    "    del sys.modules['split_llm.glm6b.utils']\n",
    "    del sys.modules['split_llm.protocols.base_protocols']\n",
    "    del sys.modules['split_llm.protocols.ss_mul_with_memory']\n",
    "    del sys.modules['split_llm.protocols.element_wise']\n",
    "    del sys.modules['split_llm.glm6b.secure_inference']\n",
    "    del sys.modules['split_llm.glm6b.wrapped_layer']\n",
    "    del sys.modules['split_llm.common.torch_utils']\n",
    "    print(\"delete complete!\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "from split_llm.glm6b.secure_inference import GLMAttentionProtocol\n",
    "from split_llm.common.torch_utils import relative_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_layer = glm.condgen.transformer.layers[0].float()\n",
    "attn_wrapped = Attention_GLM_Wrapped(4096, 32, 0)\n",
    "\n",
    "copy_attention(transformer_layer, attn_wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_llm.common.communication import Communication, Node, SimulatedCommunication\n",
    "communication = SimulatedCommunication([\"n0\", \"n1\", \"n2\"])\n",
    "communication.new_stage(\"Test\")\n",
    "\n",
    "n0 = Node(communication, \"n0\")\n",
    "n1 = Node(communication, \"n1\")\n",
    "n2 = Node(communication, \"n2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "n0.space.attentions = [attn_wrapped.cuda()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol = GLMAttentionProtocol(\n",
    "    n0, n1, n2, 0, 10, device=\"cuda\"\n",
    ")\n",
    "protocol.prepare()\n",
    "protocol.offline_execute(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.normal(0, 1, [10, 1, 4096]).cuda()\n",
    "x1 = x - x0\n",
    "n0.storage[f\"{protocol.name}:x0\"] = x0\n",
    "n1.storage[f\"{protocol.name}:x1\"] = x1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test computing QKV\n",
    "protocol.online_step_qkv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QKV error: 0.00046\n"
     ]
    }
   ],
   "source": [
    "qkv_computed = n0.storage[f\"{protocol.name}:h0\"] + n1.storage[f\"{protocol.name}:h1\"]\n",
    "print(f\"QKV error: {relative_error(qkv_computed, h_qkv):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test computing dot-product\n",
    "protocol.online_step_dot_product()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores error: 0.00048\n"
     ]
    }
   ],
   "source": [
    "computed_scores = n0.storage[f\"{protocol.name}:s0\"] + n1.storage[f\"{protocol.name}:s1\"]\n",
    "print(f\"Scores error: {relative_error(computed_scores, scores):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test computing softmax scores\n",
    "protocol.online_step_softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Scores error: 0.00056\n"
     ]
    }
   ],
   "source": [
    "computed_softmax_scores = n0.storage[f\"{protocol.name}:s0\"] + n1.storage[f\"{protocol.name}:s1\"]\n",
    "print(f\"Softmax Scores error: {relative_error(computed_softmax_scores, softmax_scores):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test compute weighted values\n",
    "protocol.online_step_weighted_v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted V error: 0.00055\n"
     ]
    }
   ],
   "source": [
    "computed_v = n0.storage[f\"{protocol.name}:h0\"] + n1.storage[f\"{protocol.name}:h1\"]\n",
    "print(f\"Weighted V error: {relative_error(computed_v, weighted_v):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]]],\n",
       "       device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0220, 0.0767, 0.0130,  ..., 0.1028, 0.0860, 0.0713]],\n",
       "\n",
       "         [[0.0172, 0.0446, 0.1339,  ..., 0.1029, 0.1990, 0.1635]],\n",
       "\n",
       "         [[0.0431, 0.0183, 0.0397,  ..., 0.0485, 0.0528, 0.0405]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.3899, 0.0645, 0.1712,  ..., 0.1365, 0.1864, 0.0897]],\n",
       "\n",
       "         [[0.1867, 0.2289, 0.2115,  ..., 0.1220, 0.0426, 0.0963]],\n",
       "\n",
       "         [[0.0352, 0.0694, 0.0859,  ..., 0.1079, 0.0551, 0.0420]]],\n",
       "\n",
       "\n",
       "        [[[0.0851, 0.0858, 0.0490,  ..., 0.1082, 0.1843, 0.0451]],\n",
       "\n",
       "         [[0.0763, 0.0539, 0.0035,  ..., 0.1005, 0.0780, 0.0459]],\n",
       "\n",
       "         [[0.0727, 0.1401, 0.2799,  ..., 0.1725, 0.0887, 0.0848]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0234, 0.1186, 0.1014,  ..., 0.0566, 0.1009, 0.1451]],\n",
       "\n",
       "         [[0.0954, 0.0188, 0.0608,  ..., 0.1078, 0.0903, 0.1563]],\n",
       "\n",
       "         [[0.0725, 0.0369, 0.0479,  ..., 0.0787, 0.2290, 0.1117]]],\n",
       "\n",
       "\n",
       "        [[[0.0211, 0.0567, 0.1949,  ..., 0.1389, 0.1557, 0.0738]],\n",
       "\n",
       "         [[0.1250, 0.0632, 0.0367,  ..., 0.0437, 0.0736, 0.0898]],\n",
       "\n",
       "         [[0.0502, 0.0399, 0.0233,  ..., 0.0992, 0.0516, 0.0727]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.1071, 0.0790, 0.0242,  ..., 0.0973, 0.0572, 0.0551]],\n",
       "\n",
       "         [[0.0456, 0.1953, 0.0519,  ..., 0.1485, 0.0563, 0.0780]],\n",
       "\n",
       "         [[0.0156, 0.0969, 0.0316,  ..., 0.0728, 0.1100, 0.1222]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0739, 0.1133, 0.0240,  ..., 0.0576, 0.3051, 0.0536]],\n",
       "\n",
       "         [[0.0520, 0.1722, 0.1277,  ..., 0.1188, 0.0374, 0.1219]],\n",
       "\n",
       "         [[0.0659, 0.0931, 0.0586,  ..., 0.1898, 0.1463, 0.1448]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0509, 0.0341, 0.0101,  ..., 0.1405, 0.0391, 0.1184]],\n",
       "\n",
       "         [[0.0948, 0.1187, 0.0576,  ..., 0.0716, 0.0286, 0.1006]],\n",
       "\n",
       "         [[0.0967, 0.0975, 0.0804,  ..., 0.0726, 0.0784, 0.1233]]],\n",
       "\n",
       "\n",
       "        [[[0.0309, 0.2450, 0.1186,  ..., 0.0910, 0.0671, 0.1037]],\n",
       "\n",
       "         [[0.0719, 0.1374, 0.0263,  ..., 0.1036, 0.0631, 0.0491]],\n",
       "\n",
       "         [[0.1934, 0.0327, 0.0805,  ..., 0.0735, 0.1763, 0.0624]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.1043, 0.1893, 0.1266,  ..., 0.0932, 0.1977, 0.1451]],\n",
       "\n",
       "         [[0.0358, 0.0153, 0.0224,  ..., 0.1227, 0.0300, 0.0817]],\n",
       "\n",
       "         [[0.0652, 0.1257, 0.1885,  ..., 0.1061, 0.0640, 0.0897]]],\n",
       "\n",
       "\n",
       "        [[[0.0473, 0.0361, 0.2479,  ..., 0.0725, 0.0182, 0.1313]],\n",
       "\n",
       "         [[0.2062, 0.0344, 0.0555,  ..., 0.1329, 0.0580, 0.0687]],\n",
       "\n",
       "         [[0.0073, 0.0876, 0.0352,  ..., 0.0945, 0.0917, 0.0541]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.1799, 0.3920, 0.2061,  ..., 0.1316, 0.0803, 0.0976]],\n",
       "\n",
       "         [[0.0959, 0.0217, 0.1525,  ..., 0.0611, 0.1914, 0.1341]],\n",
       "\n",
       "         [[0.0820, 0.1181, 0.0255,  ..., 0.0511, 0.0460, 0.0866]]]],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
