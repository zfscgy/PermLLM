{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from perm_llm.glm6b.wrapped_layer import Attention_GLM_Wrapped, copy_attention, FeedForward_GLM_Wrapped, copy_feedforward\n",
    "from perm_llm.glm6b.utils import generate_position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:12<00:00,  1.62s/it]\n"
     ]
    }
   ],
   "source": [
    "from llm_bases.chatglm6b import ChatGML6B\n",
    "glm = ChatGML6B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_bases.chatglm6b_official.modeling_chatglm import GLMBlock\n",
    "\n",
    "\n",
    "raw_glm_layers: List[GLMBlock] = glm.condgen.transformer.layers\n",
    "attentions: List[Attention_GLM_Wrapped] = []\n",
    "attentions_public: List[Attention_GLM_Wrapped] = []\n",
    "ffs: List[FeedForward_GLM_Wrapped] = []\n",
    "for i in range(28):\n",
    "    transformer_layer = raw_glm_layers[i].float()\n",
    "    \n",
    "    # The private attention layer\n",
    "    attn_wrapped = Attention_GLM_Wrapped(4096, 32, i)\n",
    "    copy_attention(transformer_layer, attn_wrapped)\n",
    "    attn_wrapped.requires_grad_(False)\n",
    "    attentions.append(attn_wrapped.cuda())\n",
    "\n",
    "    # The public attention layer\n",
    "    attn_wrapped_public = Attention_GLM_Wrapped(4096, 32, i)\n",
    "    attn_wrapped_public.qkv_weight = None\n",
    "    attn_wrapped_public.qkv_bias = None\n",
    "    attn_wrapped_public.attn_out_weight = None\n",
    "    attn_wrapped_public.attn_out_bias = None\n",
    "    attn_wrapped_public.positional_embedding = attn_wrapped.positional_embedding\n",
    "    attn_wrapped_public.requires_grad_(False)\n",
    "    attentions_public.append(attn_wrapped_public.cuda())\n",
    "\n",
    "    ff_wrapped = FeedForward_GLM_Wrapped(4096, 32, i)\n",
    "    if i == 27:\n",
    "        copy_feedforward(transformer_layer, None, ff_wrapped)\n",
    "        ff_wrapped.layernorm_out = glm.condgen.transformer.final_layernorm.float()\n",
    "    else:\n",
    "        copy_feedforward(transformer_layer, raw_glm_layers[i + 1].float(), ff_wrapped)\n",
    "    ff_wrapped.requires_grad_(False)\n",
    "    ffs.append(ff_wrapped.cuda())\n",
    "\n",
    "word_embedding = glm.condgen.transformer.word_embeddings.weight.float().cuda()\n",
    "lm_head = glm.condgen.lm_head.float().cuda()\n",
    "input_layernorm = raw_glm_layers[0].input_layernorm.float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perm_llm.common.communication import Communication, Node, SimulatedCommunication\n",
    "communication = SimulatedCommunication([\"n0\", \"n1\", \"n2\"])\n",
    "communication.new_stage(\"Test\")\n",
    "\n",
    "n0 = Node(communication, \"n0\")\n",
    "n1 = Node(communication, \"n1\")\n",
    "n2 = Node(communication, \"n2\")\n",
    "\n",
    "n0.space.attentions = attentions\n",
    "n1.space.attentions = n2.space.attentions = attentions_public\n",
    "n0.space.ffs = n1.space.ffs = ffs\n",
    "n0.space.word_embedding = word_embedding\n",
    "n0.space.input_layernorm = n1.space.input_layernorm = input_layernorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perm_llm.glm6b.secure_inference_utils import generate_scale_dict\n",
    "\n",
    "mask_scale = generate_scale_dict(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "try:\n",
    "    del sys.modules[\"perm_llm.glm6b.secure_inference\"]\n",
    "    del sys.modules[\"perm_llm.glm6b.secure_inference_utils\"]\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perm_llm.glm6b.secure_inference import GLM_Protocol\n",
    "\n",
    "whole_protocol = GLM_Protocol(n0, n1, n2, mask_scale, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "communication.new_stage(\"prepare\")\n",
    "whole_protocol.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_tensor(query: str):\n",
    "    input_ids, _, _ = glm.get_tokenization(query)\n",
    "    input_ids = input_ids[0]\n",
    "    input_selector = torch.zeros(len(input_ids), glm.n_tokens)\n",
    "    for i in range(len(input_ids)):\n",
    "        input_selector[i, input_ids[i]] = 1\n",
    "    return input_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline(prompt_len: int, generation_length: int):\n",
    "    for next_length in [prompt_len] + [1] * generation_length:\n",
    "        communication.new_stage(f\"offline_{i}\")\n",
    "        whole_protocol.offline_execute(next_length)\n",
    "\n",
    "\n",
    "def iteratively_generate(query: str, length: int):\n",
    "    input_tensor = get_input_tensor(query).cuda()\n",
    "    generation_start_tensor = input_tensor[-1:]\n",
    "    input_tensor = input_tensor[:-1, :]\n",
    "    generated_ids = []\n",
    "    for i in range(length + 1):\n",
    "        # communication.new_stage(f\"offline_{i}\")\n",
    "        # whole_protocol.offline_execute(input_tensor.shape[0])\n",
    "        communication.new_stage(f\"online_{i}\")\n",
    "        n1.storage[f\"{whole_protocol.name}:x\"] = input_tensor\n",
    "        whole_protocol.online_execute()\n",
    "        if generation_start_tensor is None:\n",
    "            next_id = n1.storage[f\"{whole_protocol.name}:z\"][0]\n",
    "            generated_ids.append(next_id)\n",
    "            print(glm.decode(generated_ids[-1]), end=' ')\n",
    "            if next_id == glm.condgen.config.eos_token_id:\n",
    "                break\n",
    "            input_tensor = torch.zeros([1, glm.n_tokens]).cuda()\n",
    "            input_tensor[0, next_id] = 1\n",
    "        else:\n",
    "            input_tensor = generation_start_tensor\n",
    "            generation_start_tensor = None\n",
    "    print(glm.decode(generated_ids), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:717: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608935911/work/torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is difficult to give an exact number of stars in the sky , as the number of stars in the universe is constantly changing due to the expansion of It is difficult to give an exact number of stars in the sky, as the number of stars in the universe is constantly changing due to the expansion of "
     ]
    }
   ],
   "source": [
    "query = \"How many stars are in the sky?\"\n",
    "generation_length = 30\n",
    "offline(len(glm.get_tokenization(query)[0][0]) - 1, generation_length + 1)\n",
    "iteratively_generate(query, generation_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n0.storage[\"transformer_layer_1/attn/dot_product:beaver_u0 appended, v0, w0\"][-1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "json.dump(communication.comm_history, open(\"temp/comm_history.json\", \"w\"), indent=4, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_protocol.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe Biden is the  4 6 th President of the United States , serving from January  2 0 ,  2 0 2 1 , until his resignation Joe Biden is the 46th President of the United States, serving from January 20, 2021, until his resignation "
     ]
    }
   ],
   "source": [
    "query = \"Tell me about Biden\"\n",
    "generation_length = 30\n",
    "offline(len(glm.get_tokenization(query)[0][0]) - 1, generation_length + 1)\n",
    "iteratively_generate(query, generation_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_retrieval/onehot_matmul:x-u\n",
      "transformer_layer_0/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_0/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_1/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_1/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_2/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_2/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_3/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_3/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_4/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_4/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_5/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_5/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_6/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_6/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_7/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_7/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_8/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_8/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_9/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_9/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_10/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_10/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_11/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_11/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_12/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_12/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_13/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_13/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_14/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_14/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_15/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_15/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_16/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_16/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_17/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_17/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_18/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_18/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_19/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_19/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_20/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_20/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_21/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_21/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_22/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_22/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_23/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_23/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_24/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_24/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_25/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_25/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_26/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_26/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_27/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:x-u\n",
      "transformer_layer_27/attn/attn_out/SS_Mul__CX_N0_Y_N1:x-u\n",
      "prediction/final_dense/SS_Mul__CX_N0_Y_N1:x-u\n",
      "bfv_cryptosystem\n",
      "embedding_retrieval/onehot_matmul:beaver_v\n",
      "embedding_retrieval/onehot_matmul:z1_cache\n",
      "embedding_retrieval/layernorm_in/perm:mask_a&b\n",
      "embedding_retrieval/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_0/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_0/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_0/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_0/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_0/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_0/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_0/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_0/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_0/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_0/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_0/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_0/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_0/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_0/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_1/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_1/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_1/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_1/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_1/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_1/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_1/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_1/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_1/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_1/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_1/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_1/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_1/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_1/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_2/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_2/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_2/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_2/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_2/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_2/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_2/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_2/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_2/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_2/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_2/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_2/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_2/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_2/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_3/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_3/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_3/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_3/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_3/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_3/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_3/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_3/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_3/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_3/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_3/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_3/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_3/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_3/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_4/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_4/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_4/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_4/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_4/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_4/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_4/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_4/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_4/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_4/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_4/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_4/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_4/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_4/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_5/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_5/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_5/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_5/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_5/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_5/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_5/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_5/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_5/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_5/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_5/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_5/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_5/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_5/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_6/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_6/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_6/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_6/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_6/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_6/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_6/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_6/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_6/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_6/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_6/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_6/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_6/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_6/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_7/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_7/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_7/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_7/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_7/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_7/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_7/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_7/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_7/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_7/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_7/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_7/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_7/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_7/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_8/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_8/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_8/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_8/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_8/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_8/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_8/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_8/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_8/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_8/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_8/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_8/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_8/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_8/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_9/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_9/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_9/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_9/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_9/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_9/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_9/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_9/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_9/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_9/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_9/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_9/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_9/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_9/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_10/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_10/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_10/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_10/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_10/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_10/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_10/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_10/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_10/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_10/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_10/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_10/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_10/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_10/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_11/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_11/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_11/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_11/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_11/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_11/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_11/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_11/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_11/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_11/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_11/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_11/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_11/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_11/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_12/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_12/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_12/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_12/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_12/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_12/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_12/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_12/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_12/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_12/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_12/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_12/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_12/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_12/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_13/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_13/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_13/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_13/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_13/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_13/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_13/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_13/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_13/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_13/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_13/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_13/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_13/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_13/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_14/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_14/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_14/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_14/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_14/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_14/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_14/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_14/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_14/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_14/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_14/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_14/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_14/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_14/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_15/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_15/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_15/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_15/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_15/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_15/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_15/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_15/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_15/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_15/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_15/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_15/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_15/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_15/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_16/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_16/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_16/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_16/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_16/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_16/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_16/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_16/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_16/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_16/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_16/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_16/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_16/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_16/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_17/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_17/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_17/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_17/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_17/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_17/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_17/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_17/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_17/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_17/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_17/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_17/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_17/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_17/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_18/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_18/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_18/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_18/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_18/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_18/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_18/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_18/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_18/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_18/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_18/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_18/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_18/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_18/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_19/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_19/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_19/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_19/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_19/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_19/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_19/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_19/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_19/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_19/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_19/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_19/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_19/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_19/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_20/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_20/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_20/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_20/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_20/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_20/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_20/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_20/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_20/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_20/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_20/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_20/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_20/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_20/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_21/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_21/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_21/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_21/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_21/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_21/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_21/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_21/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_21/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_21/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_21/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_21/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_21/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_21/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_22/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_22/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_22/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_22/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_22/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_22/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_22/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_22/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_22/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_22/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_22/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_22/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_22/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_22/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_23/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_23/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_23/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_23/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_23/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_23/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_23/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_23/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_23/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_23/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_23/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_23/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_23/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_23/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_24/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_24/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_24/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_24/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_24/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_24/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_24/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_24/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_24/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_24/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_24/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_24/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_24/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_24/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_25/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_25/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_25/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_25/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_25/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_25/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_25/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_25/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_25/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_25/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_25/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_25/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_25/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_25/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_26/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_26/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_26/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_26/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_26/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_26/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_26/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_26/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_26/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_26/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_26/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_26/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_26/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_26/ff/layernorm_out/invperm:mask_a&b\n",
      "transformer_layer_27/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_27/attn/qkv_matmul/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_27/attn/dot_product:beaver_u1 appended, v1, w1\n",
      "transformer_layer_27/attn/softmax/perm:mask_a&b\n",
      "transformer_layer_27/attn/softmax/invperm:mask_a&b\n",
      "transformer_layer_27/attn/weighted_sum:beaver_u1 appended, v1, w1\n",
      "transformer_layer_27/attn/attn_out/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "transformer_layer_27/attn/attn_out/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "transformer_layer_27/ff/layernorm_in/perm:mask_a&b\n",
      "transformer_layer_27/ff/layernorm_in/invperm:mask_a&b\n",
      "transformer_layer_27/ff/gelu/perm:mask_a&b\n",
      "transformer_layer_27/ff/gelu/invperm:mask_a&b\n",
      "transformer_layer_27/ff/layernorm_out/perm:mask_a&b\n",
      "transformer_layer_27/ff/layernorm_out/invperm:mask_a&b\n",
      "prediction/final_dense/SS_Mul__CX_N0_Y_N1:beaver_v\n",
      "prediction/final_dense/SS_Mul__CX_N0_Y_N1:z1_cache\n",
      "prediction/score_permutation:mask_a&b\n",
      "GLM__Whole:x\n",
      "embedding_retrieval/onehot_matmul:y\n",
      "embedding_retrieval/onehot_matmul:z1\n",
      "embedding_retrieval/layernorm_in:x1\n",
      "embedding_retrieval/layernorm_in:z1\n",
      "transformer_layer_0/ff:h1\n",
      "transformer_layer_0/ff/gelu:x1\n",
      "transformer_layer_0/ff/gelu:z1\n",
      "transformer_layer_1/ff:h1\n",
      "transformer_layer_1/ff/gelu:x1\n",
      "transformer_layer_1/ff/gelu:z1\n",
      "transformer_layer_2/ff:h1\n",
      "transformer_layer_2/ff/gelu:x1\n",
      "transformer_layer_2/ff/gelu:z1\n",
      "transformer_layer_3/ff:h1\n",
      "transformer_layer_3/ff/gelu:x1\n",
      "transformer_layer_3/ff/gelu:z1\n",
      "transformer_layer_4/ff:h1\n",
      "transformer_layer_4/ff/gelu:x1\n",
      "transformer_layer_4/ff/gelu:z1\n",
      "transformer_layer_5/ff:h1\n",
      "transformer_layer_5/ff/gelu:x1\n",
      "transformer_layer_5/ff/gelu:z1\n",
      "transformer_layer_6/ff:h1\n",
      "transformer_layer_6/ff/gelu:x1\n",
      "transformer_layer_6/ff/gelu:z1\n",
      "transformer_layer_7/ff:h1\n",
      "transformer_layer_7/ff/gelu:x1\n",
      "transformer_layer_7/ff/gelu:z1\n",
      "transformer_layer_8/ff:h1\n",
      "transformer_layer_8/ff/gelu:x1\n",
      "transformer_layer_8/ff/gelu:z1\n",
      "transformer_layer_9/ff:h1\n",
      "transformer_layer_9/ff/gelu:x1\n",
      "transformer_layer_9/ff/gelu:z1\n",
      "transformer_layer_10/ff:h1\n",
      "transformer_layer_10/ff/gelu:x1\n",
      "transformer_layer_10/ff/gelu:z1\n",
      "transformer_layer_11/ff:h1\n",
      "transformer_layer_11/ff/gelu:x1\n",
      "transformer_layer_11/ff/gelu:z1\n",
      "transformer_layer_12/ff:h1\n",
      "transformer_layer_12/ff/gelu:x1\n",
      "transformer_layer_12/ff/gelu:z1\n",
      "transformer_layer_13/ff:h1\n",
      "transformer_layer_13/ff/gelu:x1\n",
      "transformer_layer_13/ff/gelu:z1\n",
      "transformer_layer_14/ff:h1\n",
      "transformer_layer_14/ff/gelu:x1\n",
      "transformer_layer_14/ff/gelu:z1\n",
      "transformer_layer_15/ff:h1\n",
      "transformer_layer_15/ff/gelu:x1\n",
      "transformer_layer_15/ff/gelu:z1\n",
      "transformer_layer_16/ff:h1\n",
      "transformer_layer_16/ff/gelu:x1\n",
      "transformer_layer_16/ff/gelu:z1\n",
      "transformer_layer_17/ff:h1\n",
      "transformer_layer_17/ff/gelu:x1\n",
      "transformer_layer_17/ff/gelu:z1\n",
      "transformer_layer_18/ff:h1\n",
      "transformer_layer_18/ff/gelu:x1\n",
      "transformer_layer_18/ff/gelu:z1\n",
      "transformer_layer_19/ff:h1\n",
      "transformer_layer_19/ff/gelu:x1\n",
      "transformer_layer_19/ff/gelu:z1\n",
      "transformer_layer_20/ff:h1\n",
      "transformer_layer_20/ff/gelu:x1\n",
      "transformer_layer_20/ff/gelu:z1\n",
      "transformer_layer_21/ff:h1\n",
      "transformer_layer_21/ff/gelu:x1\n",
      "transformer_layer_21/ff/gelu:z1\n",
      "transformer_layer_22/ff:h1\n",
      "transformer_layer_22/ff/gelu:x1\n",
      "transformer_layer_22/ff/gelu:z1\n",
      "transformer_layer_23/ff:h1\n",
      "transformer_layer_23/ff/gelu:x1\n",
      "transformer_layer_23/ff/gelu:z1\n",
      "transformer_layer_24/ff:h1\n",
      "transformer_layer_24/ff/gelu:x1\n",
      "transformer_layer_24/ff/gelu:z1\n",
      "transformer_layer_25/ff:h1\n",
      "transformer_layer_25/ff/gelu:x1\n",
      "transformer_layer_25/ff/gelu:z1\n",
      "transformer_layer_26/ff:h1\n",
      "transformer_layer_26/ff/gelu:x1\n",
      "transformer_layer_26/ff/gelu:z1\n",
      "transformer_layer_27/ff:h1\n",
      "transformer_layer_27/ff/gelu:x1\n",
      "transformer_layer_27/ff/gelu:z1\n",
      "GLM__Whole:z\n",
      "transformer_layer_0/attn/dot_product:beaver_u1\n",
      "transformer_layer_0/attn/dot_product:x-u\n",
      "transformer_layer_0/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_0/attn/weighted_sum:x-u\n",
      "transformer_layer_1/attn/dot_product:beaver_u1\n",
      "transformer_layer_1/attn/dot_product:x-u\n",
      "transformer_layer_1/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_1/attn/weighted_sum:x-u\n",
      "transformer_layer_2/attn/dot_product:beaver_u1\n",
      "transformer_layer_2/attn/dot_product:x-u\n",
      "transformer_layer_2/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_2/attn/weighted_sum:x-u\n",
      "transformer_layer_3/attn/dot_product:beaver_u1\n",
      "transformer_layer_3/attn/dot_product:x-u\n",
      "transformer_layer_3/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_3/attn/weighted_sum:x-u\n",
      "transformer_layer_4/attn/dot_product:beaver_u1\n",
      "transformer_layer_4/attn/dot_product:x-u\n",
      "transformer_layer_4/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_4/attn/weighted_sum:x-u\n",
      "transformer_layer_5/attn/dot_product:beaver_u1\n",
      "transformer_layer_5/attn/dot_product:x-u\n",
      "transformer_layer_5/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_5/attn/weighted_sum:x-u\n",
      "transformer_layer_6/attn/dot_product:beaver_u1\n",
      "transformer_layer_6/attn/dot_product:x-u\n",
      "transformer_layer_6/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_6/attn/weighted_sum:x-u\n",
      "transformer_layer_7/attn/dot_product:beaver_u1\n",
      "transformer_layer_7/attn/dot_product:x-u\n",
      "transformer_layer_7/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_7/attn/weighted_sum:x-u\n",
      "transformer_layer_8/attn/dot_product:beaver_u1\n",
      "transformer_layer_8/attn/dot_product:x-u\n",
      "transformer_layer_8/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_8/attn/weighted_sum:x-u\n",
      "transformer_layer_9/attn/dot_product:beaver_u1\n",
      "transformer_layer_9/attn/dot_product:x-u\n",
      "transformer_layer_9/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_9/attn/weighted_sum:x-u\n",
      "transformer_layer_10/attn/dot_product:beaver_u1\n",
      "transformer_layer_10/attn/dot_product:x-u\n",
      "transformer_layer_10/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_10/attn/weighted_sum:x-u\n",
      "transformer_layer_11/attn/dot_product:beaver_u1\n",
      "transformer_layer_11/attn/dot_product:x-u\n",
      "transformer_layer_11/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_11/attn/weighted_sum:x-u\n",
      "transformer_layer_12/attn/dot_product:beaver_u1\n",
      "transformer_layer_12/attn/dot_product:x-u\n",
      "transformer_layer_12/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_12/attn/weighted_sum:x-u\n",
      "transformer_layer_13/attn/dot_product:beaver_u1\n",
      "transformer_layer_13/attn/dot_product:x-u\n",
      "transformer_layer_13/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_13/attn/weighted_sum:x-u\n",
      "transformer_layer_14/attn/dot_product:beaver_u1\n",
      "transformer_layer_14/attn/dot_product:x-u\n",
      "transformer_layer_14/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_14/attn/weighted_sum:x-u\n",
      "transformer_layer_15/attn/dot_product:beaver_u1\n",
      "transformer_layer_15/attn/dot_product:x-u\n",
      "transformer_layer_15/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_15/attn/weighted_sum:x-u\n",
      "transformer_layer_16/attn/dot_product:beaver_u1\n",
      "transformer_layer_16/attn/dot_product:x-u\n",
      "transformer_layer_16/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_16/attn/weighted_sum:x-u\n",
      "transformer_layer_17/attn/dot_product:beaver_u1\n",
      "transformer_layer_17/attn/dot_product:x-u\n",
      "transformer_layer_17/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_17/attn/weighted_sum:x-u\n",
      "transformer_layer_18/attn/dot_product:beaver_u1\n",
      "transformer_layer_18/attn/dot_product:x-u\n",
      "transformer_layer_18/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_18/attn/weighted_sum:x-u\n",
      "transformer_layer_19/attn/dot_product:beaver_u1\n",
      "transformer_layer_19/attn/dot_product:x-u\n",
      "transformer_layer_19/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_19/attn/weighted_sum:x-u\n",
      "transformer_layer_20/attn/dot_product:beaver_u1\n",
      "transformer_layer_20/attn/dot_product:x-u\n",
      "transformer_layer_20/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_20/attn/weighted_sum:x-u\n",
      "transformer_layer_21/attn/dot_product:beaver_u1\n",
      "transformer_layer_21/attn/dot_product:x-u\n",
      "transformer_layer_21/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_21/attn/weighted_sum:x-u\n",
      "transformer_layer_22/attn/dot_product:beaver_u1\n",
      "transformer_layer_22/attn/dot_product:x-u\n",
      "transformer_layer_22/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_22/attn/weighted_sum:x-u\n",
      "transformer_layer_23/attn/dot_product:beaver_u1\n",
      "transformer_layer_23/attn/dot_product:x-u\n",
      "transformer_layer_23/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_23/attn/weighted_sum:x-u\n",
      "transformer_layer_24/attn/dot_product:beaver_u1\n",
      "transformer_layer_24/attn/dot_product:x-u\n",
      "transformer_layer_24/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_24/attn/weighted_sum:x-u\n",
      "transformer_layer_25/attn/dot_product:beaver_u1\n",
      "transformer_layer_25/attn/dot_product:x-u\n",
      "transformer_layer_25/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_25/attn/weighted_sum:x-u\n",
      "transformer_layer_26/attn/dot_product:beaver_u1\n",
      "transformer_layer_26/attn/dot_product:x-u\n",
      "transformer_layer_26/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_26/attn/weighted_sum:x-u\n",
      "transformer_layer_27/attn/dot_product:beaver_u1\n",
      "transformer_layer_27/attn/dot_product:x-u\n",
      "transformer_layer_27/attn/weighted_sum:beaver_u1\n",
      "transformer_layer_27/attn/weighted_sum:x-u\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(n1.storage.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 130528])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1.storage[f\"{whole_protocol.name}:x\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del n0, n1, n2, whole_protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030273438"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float32(10005.03)-np.float32(10005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
